# Ce workflow a pour objectif de réaliser une analyse de séquences "RNA-seq", afin d'étudier l'expression différentielle de l'ensemble des gènes de nos échantillons. Il est écrit pour effectuer cette analyse sur des données brutes "SRA" spécifiques, disponibles sur un dépôt du ncbi (lien :https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP017413&o=acc_s%3Aa).


#####################################################################
## DEFINITION DES CONSTANTES                                       ##
#####################################################################


sra_id_list=["SRR628582","SRR628583","SRR628584","SRR628585","SRR628586","SRR628587","SRR628588","SRR628589"]

list_chr=["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","MT","X","Y"]


#####################################################################
## DEFINITION DES REGLES                                           ##
#####################################################################

### Rules
rule all:
	input: 
		"results/Snk/analysis/results.txt", "results/Snk/analysis/*.csv", "results/Snk/analysis/analyse*", "results/fastqc_results/*_1_fastqc.html", "results/fastqc_results/*_2_fastqc.html"


### Téléchargement des données de séquencage brutes .sra
rule download_sra: 
  output:
    expand("data/snk/SRA/{SRAID}.sra",SRAID=sra_id_list)
    
  run:
    for k in range(len(sra_id_list)):
      shell("wget -O data/snk/SRA/{SRAID}.sra https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos1/sra-pub-run-5/{SRAID}/{SRAID}.1".format(SRAID=sra_id_list[k]))

### Conversion des SRA en fastq
rule conversion_FASTQ: 
	input:
		expand("data/snk/SRA/{SRAID}.sra",SRAID=sra_id_list)
	output:
		"data/snk/FASTQ/{SRAID}_1.fastq.gz","data/snk/FASTQ/{SRAID}_2.fastq.gz"
	singularity: 
        	"docker://evolbioinfo/sratoolkit:v2.10.8"
	shell:
		"fastq-dump --gzip --outdir data/snk/FASTQ/ --split-files {input}"

### Téléchargement du génome de référence -- séquences de chaque chromosome pour procéder à l'alignement - version GRCh38
rule get_chr_seq: 
  output:
    expand("data/snk/chr/{CHR}.fa.gz",CHR=list_chr)
  
  run:
    for i in range(len(list_chr)):
      shell("wget -O data/snk/chr/{chr}.fa.gz ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.{chr}.fa.gz".format(chr=list_chr[i]))

### controle qualite des reads
rule fastqc :
    input :
        fastq1 = "data/snk/FASTQ/{SRAID}_1.fastq.gz",
        fastq2 = "data/snk/FASTQ/{SRAID}_2.fastq.gz"
    output :
        fastq1html = "results/fastqc_results/{SRAID}_1_fastqc.html",
        fastq2html = "results/fastqc_results/{SRAID}_2_fastqc.html"
    singularity :
        "docker://evolbioinfo/fastqc:v0.11.8"
    shell :
        "fastqc {input.fastq1} -o {output.fastq1html} "
        "fastqc {input.fastq2} -o {output.fastq2html} "
        
        
rule concatenation_genome: 
	input:
		expand("data/snk/chr/{CHR}.fa.gz",CHR=list_chr)
	output:
		"data/snk/ref/ref.fa"
	shell:
		"gunzip -c {input} > {output}"

### Alignement avec STAR. Il faut tout d'abord créer un index :	
rule make_STAR_index: # Index human genome and create many output files (use STAR container).
	input:
		"data/snk/ref/ref.fa"	
	output:
		"data/snk/ref/genomeParameters.txt"
	threads: 16
	singularity: 
        	"docker://evolbioinfo/star:v2.7.6a"
	shell:
		"""
		STAR --runThreadN {threads} --runMode genomeGenerate --genomeDir data/snk/ref/ --genomeFastaFiles {input}
		"""

    


### Obtention de fichier d'annotation du génome sous le format gff (.gtf) pour compter les reads	
rule download_genome_annotations: 
	output:
		"data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf"
	shell:
		"""
		wget ftp://ftp.ensembl.org/pub/release-101/gtf/homo_sapiens/Homo_sapiens.GRCh38.101.chr.gtf.gz > data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf.gz
		gunzip data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf.gz > {output}
		"""

### Mapping des fichiers FASTQ grâce à l'index précédemment créé avec STAR
rule map_FASTQ: 
	input:
		fq_fw="data/snk/FASTQ/{SRAID}_1.fastq.gz",fq_rv="data/snk/FASTQ/{SRAID}_2.fastq.gz"
	output:
		"data/snk/bam/{SRAID}.bam"
	threads: 16
	singularity: 
        	"docker://evolbioinfo/star:v2.7.6a"
	shell:
		"""
    STAR --outSAMstrandField intronMotif \
        --outFilterMismatchNmax 4 \
        --outFilterMultimapNmax 10 \
        --genomeDir data/snk/ref \
        --readFilesIn <(gunzip -c {input.fq_fw}) <(gunzip -c {input.fq_rv}) \
        --runThreadN {threads} \
        --outSAMunmapped None \
        --outSAMtype BAM SortedByCoordinate \
        --outStd BAM_SortedByCoordinate \
        --genomeLoad NoSharedMemory \
        --limitBAMsortRAM 7000000000 \
        --outFileNamePrefix {SRAID}  
        >{output}    
   		"""
   		
### Indexation des fichiers bam
rule index_BAM:
	input:
		"data/snk/bam/{SRAID}.bam"
	output:
		"data/snk/bam/{SRAID}.bam.bai"
	singularity: 
        	"docker://evolbioinfo/samtools:v1.11"
	shell:
		"samtools index {input} {output}"

### Comptage des reads avec featureCounts
rule count_reads: 
        input:
                gtf_file="data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf", bam=expand("data/snk/bam/{SRAID}.bam",SRAID=sra_id_list)
                
        output:
                "results/Snk/counts/counts.txt", "results/Snk/counts/output.counts.summary"
        threads: 16
        singularity: 
        	"docker://evolbioinfo/subread:v2.0.1"
        shell:
                """
                featureCounts -T {threads} -t gene -g gene_id -s 0 -a {input.gtf_file} -o results/counts/output_gene.counts {input.bam}
                """

### Comptage des exons avec featureCounts
rule count_exons: 
        input:
                gtf_file="data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf", bam=expand("data/snk/bam/{SRAID}.bam",SRAID=sra_id_list)
                
        output:
                "exons_counts.txt", "exons_counts.counts.summary"
        threads: 16
        singularity: 
        	"docker://evolbioinfo/subread:v2.0.1"
        shell:
                """
                featureCounts -T {threads} -f -s 0 -a ${gtf_file} -o results/counts/exons_counts.counts ${bam}
                """



### Analyse de l'expression différentielle avec un script R et génération des graphes et tableaux
rule counts_analysis:
	input:
		counts = "results/Snk/counts/counts.txt", exons ="results/Snk/counts/exons_counts.txt"
	output:
		"results/Snk/analysis/results.txt", "results/Snk/analysis/*.csv", "results/Snk/analysis/analyse*"
	singularity: 
		"docker://mdjaff/r-base:4.0.3"
	script:
		"Rscript diff_expr_analysis.R {input.counts}"

	
