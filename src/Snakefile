// Ce workflow a pour objectif de réaliser une analyse de séquences "RNA-seq", afin d'étudier l'expression différentielle de l'ensemble des gènes de nos échantillons. Il est écrit pour effectuer cette analyse sur des données brutes "SRA" spécifiques, disponibles sur un dépôt du ncbi (lien :https://www.ncbi.nlm.nih.gov/Traces/study/?acc=SRP017413&o=acc_s%3Aa).


#####################################################################
## DEFINITION DES CONSTANTES                                       ##
#####################################################################


sra_id_list=["SRR628582","SRR628583","SRR628584","SRR628585","SRR628586","SRR628587","SRR628588","SRR628589"]

list_chr=["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","MT","X","Y"]


#####################################################################
## DEFINITION DES REGLES                                           ##
#####################################################################

### Rules
rule all:
	input: 
		"results/Snk/analysis/results.txt", "results/Snk/analysis/*.csv", "results/Snk/analysis/analyse*"


### Téléchargement des données de séquencage brutes .sra
rule download_sra: 
  output:
    expand("data/Snk/SRA/{SRAID}.sra",SRAID=sra_id_list)
    
  run:
    for k in range(len(sra_id_list)):
      shell("wget -O data/Snk/SRA/{SRAID}.sra https://sra-downloadb.be-md.ncbi.nlm.nih.gov/sos1/sra-pub-run-5/{SRAID}/{SRAID}.1".format(SRAID=sra_id_list[k]))

### Conversion des SRA en fastq
rule conversion_FASTQ: # Create two fastq.gz files for each .sra file (use sratoolkit container). One file contains the genetic sequence in 5'3' and the other in 3'5'.
	input:
		"data/Snk/SRA/{SRAID}.sra"
	output:
		"data/Snk/FASTQ/{SRAID}_1.fastq.gz","data/Snk/FASTQ/{SRAID}_2.fastq.gz"
	container:
        	"docker://evolbioinfo/sratoolkit:v2.10.8"
	shell:
		"fastq-dump --gzip --outdir data/Snk/FASTQ/ --split-files {input}"

### Téléchargement du génome de référence -- séquences de chaque chromosome pour procéder à l'alignement - version GRCh38
rule get_chr_seq: 
  output:
    expand("data/Snk/chr/{CHR}.fa.gz",CHR=list_chr)
  
  run:
    for i in range(len(list_chr)):
      shell("wget -O data/Snk/chr/{chr}.fa.gz ftp://ftp.ensembl.org/pub/release-101/fasta/homo_sapiens/dna/Homo_sapiens.GRCh38.dna.chromosome.{chr}.fa.gz".format(chr=list_chr[i]))


rule concatenation_genome: # Unzip human genome and put it in the ref folder.
	input:
		expand("data/Snk/chr/{CHR}.fa.gz",CHR=list_chr)
	output:
		"data/Snk/ref/ref.fa"
	shell:
		"gunzip -c {input} > {output}"

### Alignement avec STAR. Il faut tout d'abord créer un index :	
rule make_STAR_index: # Index human genome and create many output files (use STAR container).
	input:
		"data/Snk/ref/ref.fa"	
	output:
		"data/Snk/ref/chrLength.txt","ref/chrName.txt","ref/chrNameLength.txt","ref/chrStart.txt","ref/genomeParameters.txt","ref/Genome","ref/SA","ref/SAindex"
	threads: 16
	container:
        	"docker://evolbioinfo/star:v2.7.6a"
	shell:
		"STAR --runThreadN {threads} --runMode genomeGenerate --genomeDir ref/ --genomeFastaFiles {input}"


### Obtention de fichier d'annotation du génome sous le format gff (.gtf) pour compter les reads	
rule download_genome_annotations: 
	output:
		"data/snk/GenomeAnnotation/Homo_sapiens.GRCh38.101.chr.gtf"
	shell:
		"""
		wget ftp://ftp.ensembl.org/pub/release-101/gtf/homo_sapiens/Homo_sapiens.GRCh38.101.chr.gtf.gz
		gunzip Homo_sapiens.GRCh38.101.chr.gtf.gz
		"""

### Mapping des fichiers FASTQ grâce à l'index précédemment créé avec STAR
rule map_FASTQ: 
	input:
		fq_fw="data/Snk/FASTQ/{SRAID}_1.fastq.gz",fq_rv="data/Snk/FASTQ/{SRAID}_2.fastq.gz", chr_index="ref/chrLength.txt"
	output:
		"data/Snk/bam/{SRAID}.bam"
	threads: 16
	container:
        	"docker://evolbioinfo/star:v2.7.6a"
	shell:
		"""
    STAR --outSAMstrandField intronMotif \
        --outFilterMismatchNmax 4 \
        --outFilterMultimapNmax 10 \
        --genomeDir ref \
        --readFilesIn <(gunzip -c {input.fq_fw}) <(gunzip -c ${fq_rv}) \
        --runThreadN {threads} \
        --outSAMunmapped None \
        --outSAMtype BAM SortedByCoordinate \
        --outStd BAM_SortedByCoordinate \
        --genomeLoad NoSharedMemory \
        --limitBAMsortRAM 7000000000 \
        --outFileNamePrefix {SRAID}  
        >{output}    
   		"""
   		
### Indexation des fichiers bam
rule index_BAM:
	input:
		"data/Snk/bam/{SRAID}.bam"
	output:
		"data/Snk/bam/{SRAID}.bam.bai"
	container:
        	"docker://evolbioinfo/samtools:v1.11"
	shell:
		"samtools index {input} {output}"

### Comptage des reads avec featureCounts
rule count_reads: 
        input:
                annot="Homo_sapiens.GRCh38.101.chr.gtf", bam_files=expand("data/Snk/bam/{SRAID}.bam",SRAID=sra_id_list),bai_files=expand("data/Snk/bam/{SRAID}.bam.bai",SRAID=sra_id_list)
                
        output:
                "results/Snk/counts/gene_output.counts"
        threads: 16
        container:
        	"docker://evolbioinfo/subread:v2.0.1"
        shell:
                "featureCounts -p -T {threads} -t gene -g gene_id -s 0 -a {input.annot} -o {output} {input.bam_files}"


### Analyse de l'expression différentielle avec un script R et génération des graphes et tableaux
rule statsAnalysis: # Statistical analysis on the samples, using the counting of reads per gene done in the gene_count rule.
	input:
		"gene_output.counts"
	output:
		"results/Snk/analysis/results.txt", "results/Snk/analysis/*.csv", "results/Snk/analysis/analyse*"
	container:
		"docker://mdjaff/r-base:4.0.3"
	script:
		"Rscript diff_expr_analysis.R {input}"

	
